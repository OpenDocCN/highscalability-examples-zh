# 策略：缓存 404 在服务器时间上节省了洋葱 66％

> 原文： [http://highscalability.com/blog/2010/3/26/strategy-caching-404s-saved-the-onion-66-on-server-time.html](http://highscalability.com/blog/2010/3/26/strategy-caching-404s-saved-the-onion-66-on-server-time.html)

![](img/cfdc345e67ee6ab77afd7b46784522a3.png)

在 [The Onion Use Django，以及为什么它对我们如此重要](http://www.reddit.com/r/django/comments/bhvhz/the_onion_uses_django_and_why_it_matters_to_us/)一文中，他们提出了许多有趣的观点，说明了他们雄心勃勃的基础架构从 Drupal / PHP 迁移到 Django / Python：这一步并不难， 由于他们之前有移动 AV 的经验，所以花了时间和工作 俱乐部网站； 核心框架 API 的混乱使移动比停留更具吸引力； 支持站点旧版本的结构是一个尚未解决的问题； 内置的 Django 管理员节省了大量工作； 通过“减少专业化或黑客攻击的碎片”，团体开发变得更加容易； 他们使用 IRC 进行分布式开发； 狮身人面像用于全文搜索； nginx 是媒体服务器和反向代理； haproxy 将启动过程设为 5 秒程序； Capistrano 用于部署； 清洁的组件分离使移动更加容易； Git 版本控制； 具有复杂查询集的 ORM 是一个性能问题。 memcached 用于缓存渲染的页面； CDN 每 10 分钟检查一次更新； 视频，文章，图像和 404 页均由 CDN 提供。

但是最令人惊讶的一点是：

> 最大的性能提升是：缓存 404 并在 404 上将 Cache-Control 标头发送到 CDN。我们多达 66％的服务器时间都花在了从蜘蛛爬取无效的 url 和从野外存在的 url 中提供 404 的服务中 6-10 年前。 [编辑：实施更改后，我们的出站带宽减少了约 66％，Web 服务器群集上的平均负载减少了约 50％]。
> 
> 我们的链接中的一小部分来自旧内容，而我不再知道其网址。 我们重定向了 5 年前的所有内容。 最初在 6 到 10 年前发布的东西可能会被重定向，但是它们都不来自数据库，并且最初都是静态 HTML，在我开始为 The Onion 工作之前就没有维护重定向。

> 蜘蛛占我 404 的绝大多数。 他们请求的 URI 根本不在我们的标记中。 我无法修复损坏的蜘蛛，并告诉它不要请求甚至不存在的这些链接，但是我仍然必须服务于它们的 404。

> CDN 未缓存我们的 404 页。 允许对它们进行缓存，可以将原始渗透率大大降低，与未缓存的 404 相比，输出带宽减少了 66％。

> Edit: This is not to say that our 404s were not cached at our origin. Our precomputed 404 was cached and served out without a database hit on every connection, however this still invokes the regular expression engine for url pattern matching and taxes the machine's network IO resources.

无意开玩笑，讽刺或讽刺。 这些流量大部分来自蜘蛛，它们正在寻找组成页面，因此保留 URL 并不是问题。 问题是减少了这些有毒蜘蛛的影响，并且将 404 页缓存为解毒剂。 即使您像 The Onion 一样已经有十多年没有上网了，但仍然很容易就可以找到很多东西。

## 相关文章

*   [文章](http://news.ycombinator.com/item?id=1219133)上的 Hacker News Thread，其中 John Onion 耐心地尝试解释为什么 The Onion 没有惹恼广告收入。
*   [HTTP 404 响应代码](http://en.wikipedia.org/wiki/HTTP_404)
*   [Fighting Linkrot](http://www.useit.com/alertbox/980614.html) by **[Jakob Nielsen](http://www.useit.com/jakob/ "Author biography")**

404 占很大比例的原因是因为洋葱是 CDNed：合法的（非 404）请求主要由 CDN 服务。 但是由于 404 被 CDN 缓存，所以 CDN 将请求发送到原始服务器。 因此 404 会在原始服务器上的点击中占不成比例的百分比。

如何阻止其中一些蜘蛛？ 任何人都有一个很好的坏蜘蛛清单。
我读过一个博客 Bing Spider，它会在短时间内在某些网页上重复查询，这给网站带来了负担。 因此，所有者必须禁止它。

行动不便的洋葱。.如果那些记忆力很强的爬虫恰好是 googlebot，则您会以 SEO 的形式浪费大量收入。 几年前的旧页等于从 800 磅重的怀抱中走了出来。 大猩猩/蜘蛛/章鱼/大象在房间里。

“大部分流量来自蜘蛛寻找的组成页面，因此保留 URL 并不是问题。”

如果按您的平均水平说超过 50％，那么他们仍然会丢弃高达 25％的流量。 除此之外，爬虫只会抓取其他网站的链接，因此它们也放弃了传入链接的 SEO 优势。 他们写有趣的故事是一件好事。 :-)

“行动不便的洋葱。如果那些记忆力很强的爬虫恰好是 googlebot，您会以 SEO 的形式浪费大量收入。几年前的旧书等于从 800 磅重的大抱抱。大猩猩/蜘蛛/章鱼/大象 -在房间里。”
他们不会放弃，只是将压力从服务器到 CDN 来处理这种 404 页。
因此，在进行此更改之前，当您从服务器请求某个不存在的站点时，它就像：
客户端-> CDN->源服务器，然后再返回 CDN 和客户端。
现在，当有人请求页面时，CDN 会检查其缓存（如果找不到或不允许从缓存中提供服务），然后请求为该页面提供服务的 Origin Server，如果那是 404，则发送标头 告诉 CDN 缓存该页面。
因此，下一次该请求将直接从 CDN 的本地缓存中提供。

泰瑞尔